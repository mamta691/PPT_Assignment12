{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cad3d90-1de0-4433-8470-d909624b8c98",
   "metadata": {},
   "source": [
    "# General Linear Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3628e37f-0f52-404f-8cf3-584621a22dcc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. What is the purpose of the General Linear Model (GLM)?\n",
    "\n",
    "The General Linear Model (GLM) is a useful framework for comparing how several variables affect different continuous variables. In its simplest form, GLM is described as:\n",
    "Data = Model + Error (Rutherford, 2001, p.3)\n",
    "\n",
    "# 2. What are the key assumptions of the General Linear Model?\n",
    "\n",
    "Assumptions:\n",
    "    \n",
    "The data are independently distributed, i.e., cases are independent.\n",
    "The dependent variable \n",
    " does NOT need to be normally distributed, but it typically assumes a distribution from an exponential family (e.g. binomial, Poisson, multinomial, normal, etc.).\n",
    "A GLM does NOT assume a linear relationship between the response variable and the explanatory variables, but it does assume a linear relationship between the transformed expected response in terms of the link function and the explanatory variables; e.g., for binary logistic regression \n",
    ".\n",
    "Explanatory variables can be nonlinear transformations of some original variables.\n",
    "The homogeneity of variance does NOT need to be satisfied. In fact, it is not even possible in many cases given the model structure.\n",
    "Errors need to be independent but NOT normally distributed.\n",
    "Parameter estimation uses maximum likelihood estimation (MLE) rather than ordinary least squares (OLS).\n",
    "\n",
    "# 3. How do you interpret the coefficients in a GLM?\n",
    "\n",
    "The intercept term is the intercept in the linear part of the GLM equation, so your model for the mean is E[Y]=g−1(Xβ)\n",
    ", where g\n",
    " is your link function and Xβ\n",
    " is your linear model. This linear model contains an \"intercept term\", i.e.:\n",
    "\n",
    "Xβ=c+X1β1+X2β2+⋯\n",
    "In your case the intercept is significantly non-zero, but the variable is not, so it is saying that\n",
    "\n",
    "Xβ=c≠0\n",
    "Because your link function is binomial, then\n",
    "\n",
    "g(μ)=ln(μ1−μ)\n",
    "And so with just the intercept term, your fitted model for the mean is:\n",
    "\n",
    "E[Y]=11+e−c\n",
    "You can see that if c=0\n",
    " then this corresponds to simply a 50:50 chance of getting Y=1 or 0, i.e. E[Y]=11+1=0.5\n",
    "So your result is saying that you can't predict the outcome, but one class (1's or 0's) is more likely than the other.\n",
    "\n",
    "# 4. What is the difference between a univariate and multivariate GLM?\n",
    "\n",
    "The term univariate analysis refers to the analysis of one variable. You can remember this because the prefix “uni” means “one.”\n",
    "\n",
    "The term multivariate analysis refers to the analysis of more than one variable. You can remember this because the prefix “multi” means “more than one.”\n",
    "\n",
    "# 5. Explain the concept of interaction effects in a GLM.\n",
    "The interaction effect is the difference in main effect with other categories on other variables. So the eight one (YEAR2*ORGAN2) is the difference between observations with year1 and organ1 versus year2 and organ2 (in addition to the main effect).\n",
    "\n",
    "# 6. How do you handle categorical predictors in a GLM?\n",
    "we propose a methodology to cluster the categories of categorical predictors in Generalized Linear Models (GLM). The goal is to split the categories of each categorical predictor into a number of clusters, such that categories in the same cluster have a similar impact in the model and thus can be grouped together.\n",
    "\n",
    "#7. What is the purpose of the design matrix in a GLM?\n",
    "Using the General Linear Model (GLM), the statistical model specified in a design matrix is compared with the measured time course at each voxel. The comparison of the model and the data is expressed as an R or F value for each voxel which tells how good the overall model fits or explains the data.\n",
    "\n",
    "# 8. How do you test the significance of predictors in a GLM?\n",
    "Using the General Linear Model (GLM), the statistical model specified in a design matrix is compared with the measured time course at each voxel. The comparison of the model and the data is expressed as an R or F value for each voxel which tells how good the overall model fits or explains the data.\n",
    "#9. What is the difference between Type I, Type II, and Type III sums of squares in a GLM?\n",
    ") Type II is only when you don't have an interaction term.\n",
    "\n",
    "2) Type I vs Type III to test the interaction term...I go Type I all the time reason is this\n",
    "\n",
    "Type I SS for dv ~ A + B + A*B depends on order so...its sequential SS(A) SS(B|A) SS(A*B|A B)\n",
    "\n",
    "This is great to test your interaction...but not great to test the main effects since the effect of B is dependent on A.\n",
    "\n",
    "Type II gets around this SS(A|B) SS(B|A)\n",
    "\n",
    "Which looks great to test your main effects IF there is no interaction term.\n",
    "\n",
    "Type III: SS(A| A*B B) SS(B| A*B A)\n",
    "\n",
    "Which given the most common hypotheses...doesn't seem very useful since most people are interested in the interaction term, not the main effects when an interaction term is present.\n",
    "\n",
    "So in this case I'd use Type-I to test the interaction term. If not significant I'd refit without the interaction term and use Type-II to test the main effects.\n",
    "\n",
    "warning: anova() in R is Type-I, to get Type-II (or III) use the Anova() in the car package.\n",
    "# 10. Explain the concept of deviance in a GLM.\n",
    "\n",
    "Deviance is a measure of goodness of fit of a generalized linear model1. It is a measure of badness of fit, with higher numbers indicating worse fit1. R reports two forms of deviance – the null deviance and the residual deviance1. The residual deviance tells us how well the response variable can be predicted by the specific model that we fit with p predictor variables2. The lower the value, the better the model is able to predict the value of the response variable2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b5b6a-738b-4fdf-9b07-91a49720e871",
   "metadata": {},
   "source": [
    "# Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6562ca-e9b6-415f-8ef8-ad4eae00756b",
   "metadata": {},
   "source": [
    "\n",
    "# 11. What is regression analysis and what is its purpose?\n",
    "Regression analysis is a set of statistical methods used for estimating relationships between a dependent variable and one or more independent variables1. The primary purpose of regression analysis is to describe the relationship between variables23. It can also be used to:\n",
    "Assess the strength of the relationship between variables1\n",
    "Estimate the value of one variable using the known values of other variables3\n",
    "Predict results and shifts in a variable based on its relationship with other variables3\n",
    "# 12. What is the difference between simple linear regression and multiple linear regression?\n",
    "\n",
    "The main differences between simple linear regression and multiple linear regression are12345:\n",
    "Simple linear regression has only one x and one y variable. Multiple linear regression has one y and two or more x variables.\n",
    "Simple linear regression occurs in 2 dimensions, while multiple linear regression can occur in an infinite number of dimensions.\n",
    "Simple linear regression is used when you have only one predictor, or X variable, predicting the response or Y variable. Multiple regression is used when you have multiple X predictors that all contribute to predicting Y.\n",
    "In simple linear regression, a criterion variable is predicted from one predictor variable. In multiple regression, the criterion is predicted by two or more variables.\n",
    "\n",
    "# 13. How do you interpret the R-squared value in regression?\n",
    "R-squared is a statistical measure that indicates how well the regression model fits the observed data values12. The most common interpretation of r-squared is how well the regression model explains observed data. For example, an r-squared of 60% reveals that 60% of the variability observed in the target variable is explained by the regression model. Generally, a higher r-squared indicates more variability is explained by the model1.\n",
    "#14. What is the difference between correlation and regression?\n",
    "The difference between correlation and regression are12:\n",
    "Correlation is a measure of the linear relationship between two variables, while regression is a measure of the numerical relationship between an independent variable and a dependent variable.\n",
    "Correlation is used to represent the association of two variables, while regression is used to fit the best line and estimate one variable based on the other variable.\n",
    "Learn more:\n",
    "1. vedantu.com\n",
    "2. keydifferences.com\n",
    "\n",
    "# 15. What is the difference between the coefficients and the intercept in regression?\n",
    "For this reason, the parameters βj, j = 1, 2, …, p β j, j = 1, 2, …, p are often called partial regression coefficients. The parameter β0 β 0 is of course separately called the intercept. In simple linear regression we have p = 1 p = 1 and the regression coefficient β1 β 1 is simply called the slope.\n",
    "\n",
    "# 16. How do you handle outliers in regression analysis?\n",
    "There are many possible approaches to dealing with outliers in regression analysis, including removing them from the observations, treating them (for example, capping the extreme observations at a reasonable value), or using algorithms that are well-suited for dealing with such values on their own1. One approach to identifying outliers is to sort the dataset in ascending order, calculate the 1st and 3rd quartiles (Q1, Q3), compute IQR=Q3-Q1, compute lower bound = (Q1–1.5IQR), upper bound = (Q3+1.5IQR), loop through the values of the dataset and check for those who fall below the lower bound and above the upper bound and mark them as2.\n",
    "Learn more:\n",
    "1. developer.nvidia.com\n",
    "2. analyticsv\n",
    "\n",
    "# 17. What is the difference between ridge regression and ordinary least squares regression?\n",
    "Ridge regression differs from ordinary least squares regression in the following ways1234:\n",
    "Ridge regression produces a lower test mean squared error compared to least squares regression when multicollinearity is present1.\n",
    "Ridge regression uses a ridge estimator to estimate the coefficients, which is biased but has lower variance than the OLS estimator2.\n",
    "Ridge regression tries to find the coefficients that minimize the mean squared error and wants the magnitude of coefficients to be as small as possible3.\n",
    "Ridge regression adds just enough bias to make the estimates reasonably reliable approximations to true population values4.\n",
    "# \n",
    "# 18. What is heteroscedasticity in regression and how does it affect the model?\n",
    "Heteroscedasticity is a problem in regression analysis that results in an unequal scatter of the residuals1. It increases the variance of the regression coefficient estimates, but the regression model doesn’t pick up on this2. This leads to p-values that are smaller than they should be, as the OLS procedure does not detect the increase in variance3. As a result, the results of the analysis become hard to trust2.\n",
    "\n",
    "# 19. How do you handle multicollinearity in regression analysis?\n",
    "To deal with multicollinearity in regression, you can1234:\n",
    "Remove some of the highly correlated independent variables.\n",
    "Linearly combine the independent variables, such as adding them together.\n",
    "Use partial least squares regression to create a set of uncorrelated components to include in the model.\n",
    "Use LASSO and Ridge regression, which are advanced forms of regression analysis that can handle multicollinearity.\n",
    "Combine the variables.\n",
    "\n",
    "# 20. What is polynomial regression and when is it used?\n",
    "Polynomial regression is used to fit a regression model that describes the relationship between one or more predictor variables and a numeric response variable123. You should use polynomial regression when13:\n",
    "The relationship between the predictor variable(s) and the response variable is non-linear.\n",
    "The response variable is a continuous numeric variable.\n",
    "The points in the data are not captured by the Linear Regression Model and the Linear Regression fails in describing the best result clearly2.\n",
    "The independent variables (the factors you are using to predict with) each have a non-linear relationship with the output variable (what you want to predict)3.\n",
    "Polynomial regression is used in many experimental procedures to produce the outcome using this equation4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a728ec-3a5c-423c-9faf-061aa92b1781",
   "metadata": {},
   "source": [
    "# Loss function:\n",
    "\n",
    "# 21. What is a loss function and what is its purpose in machine learning?\n",
    "A loss function is a mathematical function that measures how well a machine learning algorithm models a dataset1234. \n",
    "It is used to evaluate how well the algorithm is predicting the expected outcome2. \n",
    "The loss function is determined as the difference between the actual output and the predicted output from the model for the single training example, while the average of the loss function for all the training examples is termed as the cost function3\n",
    "\n",
    "# 22. What is the difference between a convex and non-convex loss function?\n",
    " if a function is a non-convex loss function without plotting the graph \" by using Calculus. To quote Wikipedia's convex function article: \" If the function is twice differentiable, and the second derivative is always greater than or equal to zero for its entire domain, then the function is convex.\n",
    "\n",
    "\n",
    "# 23. What is mean squared error (MSE) and how is it calculated?\n",
    "Mean Squared Error (MSE) is a statistical measure that assesses the average squared difference between the observed and predicted values1234. It is a row-level error calculation where the difference between the prediction and the actual is squared1. MSE is the aggregated mean of these errors, which helps us understand the model performance over the whole dataset1.\n",
    "\n",
    "# 24. What is mean absolute error (MAE) and how is it calculated?\n",
    "Mean Absolute Error (MAE) is a statistical metric that measures the average size of the errors between paired observations123. It is calculated as the average absolute difference between the actual and predicted values, without taking their direction into account13. MAE is used to evaluate the performance of regression models, where lower values indicate better accuracy13.\n",
    "\n",
    "# 25. What is log loss (cross-entropy loss) and how is it calculated?\n",
    "Log Loss, also known as binary cross-entropy loss, is a loss function used in logistic regression and extensions of it such as neural networks12. It is defined as the negative log-likelihood of a logistic model that returns y_pred probabilities for its training data y_true2. The equation for binary cross-entropy loss is L(t, p) = − (t. log(p) + (1 − t). log(1 − p))1.\n",
    "\n",
    "# 26. How do you choose the appropriate loss function for a given problem?\n",
    "you can choose a loss function that is appropriate for your problem. Some common loss functions include mean squared error, cross-entropy, hinge loss, and log loss. It is also important to evaluate the performance of your model using the chosen loss function and make adjustments as necessary.\n",
    "\n",
    "# 27. Explain the concept of regularization in the context of loss functions.\n",
    "Regularization means restricting a model to avoid overfitting by shrinking the coefficient estimates to zero. When a model suffers from overfitting, we should control the model's complexity. Technically, regularization avoids overfitting by adding a penalty to the model's loss function: \n",
    "    Regularization = Loss Function + Penalty\n",
    "\n",
    "# 28. What is Huber loss and how does it handle outliers?\n",
    "Huber loss is a loss function that is commonly used in regression problems to balance the effects of outliers and inliers in the data. Unlike the mean squared error (MSE) loss, which treats all errors equally, the Huber loss gives less weight to large errors, making it more robust to outliers.\n",
    "\n",
    "# 29. What is quantile loss and when is it used?\n",
    "\n",
    "the quantile regression loss function is applied to predict quantiles.\n",
    "A quantile is the value below which a fraction of observations in a group falls. \n",
    "For example, a prediction for quantile 0.9 should over-predict 90% of the times. Given a prediction yip and outcome yi,\n",
    "\n",
    "# 30. What is the difference between squared loss and absolute loss?\n",
    "If the prediction error causes the client's loss (e.g. financial loss) to grow quadratically and symmetrically about zero, you are facing square prediction loss.\n",
    "If the client's loss grows linearly and symmetrically about zero, you are facing absolute prediction loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282fdb5-48fb-4219-9be6-f32a4569683f",
   "metadata": {},
   "source": [
    "# Optimizer (GD):\n",
    "\n",
    "# 31. What is an optimizer and what is its purpose in machine learning?\n",
    "An optimizer is a machine learning algorithm that helps improve the accuracy of training models. \n",
    "It is typically implemented as a subroutine in deep neural networks,\n",
    "and it has the ability to make small changes to the parameters of an optimization algorithm.\n",
    "# 32. What is Gradient Descent (GD) and how does it work?\n",
    "radient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates.\n",
    "Until the function is close to or equal to zero, the model will continue to adjust its parameters to yield the smallest possible error. Once machine learning models are optimized for accuracy, they can be powerful tools for artificial intelligence (AI) and computer science applications.\n",
    "\n",
    "# 33. What are the different variations of Gradient Descent?\n",
    "Gradient descent is an optimization algorithm that's used when training a machine learning model1. It tweaks its parameters iteratively to minimize a given function to its local minimum1.There are three types of gradient descent learning algorithms21:\n",
    "Batch gradient descent: updates the model only after all training examples have been evaluated21.\n",
    "Stochastic gradient descent: updates the model after each training example2.\n",
    "Mini-batch gradient descent: updates the model after a small subset of training examples2.\n",
    "\n",
    "# 34. What is the learning rate in GD and how do you choose an appropriate value?\n",
    "Learning rate is used to scale the magnitude of parameter updates during gradient descent. The choice of the value for learning rate can impact two things: 1) how fast the algorithm learns and 2) whether the cost function is minimized or not.\n",
    "\n",
    "# 35. How does GD handle local optima in optimization problems?\n",
    "\n",
    "Gradient Descent is an optimization algorithm that finds the local minima of a differentiable function. \n",
    "It is an iterative algorithm that starts with an initial guess for the optimal solution and iteratively adjusts the parameters to minimize the cost function.\n",
    "Gradient descent can get stuck in local minima, which are suboptimal solutions that are not the global minimum. \n",
    "To avoid this problem, several techniques have been developed such as momentum, Nesterov accelerated gradient, Adagrad, Adadelta, RMSprop, and Adam12. These techniques help gradient descent to escape from local minima and converge to the global minimum.\n",
    "\n",
    "# 36. What is Stochastic Gradient Descent (SGD) and how does it differ from GD?\n",
    "The main difference between stochastic gradient descent (SGD) and gradient descent (GD) is the number of data points used before each update of the parameters. GD spans over the entire dataset once before each update, whereas SGD randomly takes just one data point for each update12. In GD, you have to run through all the samples in your training set to do a single update for a parameter in a particular iteration, whereas in SGD, you use only one or a subset of training samples from your training set to do the update for a parameter in a particular iteration2.\n",
    "\n",
    "# 37. Explain the concept of batch size in GD and its impact on training.\n",
    "using a batch equal to the entire dataset guarantees convergence to the global optima of the objective function. However, this is at the cost of slower, empirical convergence to that optima. On the other hand, using smaller batch sizes have been empirically shown to have faster convergence to “good” solutions.\n",
    "\n",
    "# 38. What is the role of momentum in optimization algorithms?\n",
    "Momentum is an optimization technique that improves on gradient descent by reducing oscillatory effects and acting as an accelerator for optimization problem solving12. It finds the global (and not just local) optimum, and is commonly used in machine learning and has broad applications to all optimizers through SGD1. The basic idea behind momentum is to decrease the convergence time by accelerating Gradient Descent in a relevant and optimal direction3. It is widely used in deep learning applications and is an important optimization technique for training deep neural networks2.\n",
    "# 39. What is the difference between batch GD, mini-batch GD, and SGD?\n",
    "Mini-batch Gradient Descent:\n",
    "    \n",
    "Imagine taking your dataset and dividing it into several chunks, or batches. So instead of waiting until the algorithm runs through the entire dataset to only after update the weights and bias, it updates at the end of each, so-called, mini-batch. This allows us to move quickly to the global minimum in the cost function and update the weights and biases multiple times per epoch now. The most common mini-batch sizes are 16, 32, 64, 128, 256, and 512. Most of the projects use Mini-batch GD because it is faster in larger datasets.\n",
    "\n",
    "# Mini-batch Gradient Descent:\n",
    "X = data_input\n",
    "Y = labels\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "for i in range(0, num_iterations):\n",
    "\t\n",
    "\tminibatches = random_mini_batches(X, Y, mini_batch_size)\n",
    "        for minibatch in minibatches:\n",
    "            # Select a minibatch\n",
    "\t    (minibatch_X, minibatch_Y) = minibatch\n",
    "\t    # Forward propagation\n",
    "\t    a, caches = forward_propagation(X, parameters)\n",
    "\t    # Compute cost.\n",
    "\t    cost += compute_cost(a, Y)\n",
    "\t    # Backward propagation.\n",
    "\t    grads = backward_propagation(a, caches, parameters)\n",
    "\t    # Update parameters.\n",
    "\t    parameters = update_parameters(parameters, grads)\n",
    "To prepare the mini-batches, one most apply some preprocessing steps: randomizing the dataset to randomly split the dataset and then partitioning it in the right number of chunks. But what happens if we chose to set the number of batches to 1 or equal to the number of training examples?\n",
    "\n",
    "# Batch Gradient Descent\n",
    "As stated before, in this gradient descent, each batch is equal to the entire dataset. That is:\n",
    "\n",
    "\n",
    "Where {1} denotes the first batch from the mini-batch. The downside is that it takes too long per iteration. This method can be used to training datasets with less than 2000 training examples.\n",
    "\n",
    "(Batch) Gradient Descent:\n",
    "    \n",
    "X = data_input\n",
    "Y = labels\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "for i in range(0, num_iterations):\n",
    "    # Forward propagation\n",
    "    a, caches = forward_propagation(X, parameters)\n",
    "    # Compute cost.\n",
    "    cost += compute_cost(a, Y)\n",
    "    # Backward propagation.\n",
    "    grads = backward_propagation(a, caches, parameters)\n",
    "    # Update parameters.\n",
    "    parameters = update_parameters(parameters, grads)\n",
    "# Stochastic Gradient Descent\n",
    "On another hand, in this method, each batch is equal to one example from the training set. In this example, the first mini-batch is equal to the first training example:\n",
    "\n",
    "\n",
    "Where (1) denotes the first training example. Here the downside is that it loses the advantage gained from vectorization, has more oscillation but converges faster.\n",
    "\n",
    "Stochastic Gradient Descent:\n",
    "    \n",
    "X = data_input\n",
    "Y = labels\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "for i in range(0, num_iterations):\n",
    "    for j in range(0, m):\n",
    "        # Forward propagation\n",
    "        a, caches = forward_propagation(X[:,j], parameters)\n",
    "        # Compute cost\n",
    "        cost += compute_cost(a, Y[:,j])\n",
    "        # Backward propagation\n",
    "        grads = backward_propagation(a, caches, parameters)\n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads)\n",
    "# 40. How does the learning rate affect the convergence of GD?\n",
    "If α is too small your convergence will be slow and\n",
    "you could end up stuck on a plateau or a local minimum.\n",
    "That's why most learning rate schemes start with somewhat larger learning rates for quick gains and then reduce the learning rate gradually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e146c2-f8b4-4a94-9488-e9179abc1356",
   "metadata": {},
   "source": [
    "\n",
    "# Regularization:\n",
    "\n",
    "# 41. What is regularization and why is it used in machine learning?\n",
    "to prevent overfitting or underfitting\n",
    "Regularization is a technique in machine learning that is used to prevent overfitting or underfitting123. It involves adding a penalty term to the loss function during training, which encourages the model to choose simpler solutions that generalize better to new data2. By using regularization, we can fit our machine learning model appropriately on a given test set and hence reduce the errors in it13.\n",
    "# 42. What is the difference between L1 and L2 regularization?\n",
    "The main differences between L1 and L2 regularization are12345:\n",
    "L1 regularization tries to estimate the median of the data while L2 regularization tries to estimate the mean of the data to avoid overfitting1.\n",
    "L1 regularization adds the “absolute value of magnitude” of the coefficient as a penalty term to the loss function while L2 regularization adds the “squared magnitude” of the coefficient as the penalty term to the loss function2.\n",
    "L1 tends to shrink coefficients to zero whereas L2 tends to shrink coefficients evenly3.\n",
    "L1 can be a form of feature elimination in linear regression while L2 regularization comes from the MAP of a Normal Distributed prior while the L1 comes from a Laplacean prior5.\n",
    "\n",
    "# 43. Explain the concept of ridge regression and its role in regularization.\n",
    "Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity. This method performs L2 regularization. When the issue of multicollinearity occurs, least-squares are unbiased, and variances are large, this results in predicted values being far away from the actual values.\n",
    "# 44. What is the elastic net regularization and how does it combine L1 and L2 penalties?\n",
    "Elastic net is a method that linearly combines L1 and L2 regularization with the goal to acquire the best of both worlds123. Ridge utilizes an L2 penalty and lasso uses an L1 penalty. With elastic net, you don't have to choose between these two models, because elastic net uses both the L2 and the L1 penalty1. \n",
    "The ElasticNet mixing parameter determines the ratio of L1 and L2 penalties3.\n",
    "# 45. How does regularization help prevent overfitting in machine learning models?\n",
    "Regularization means restricting a model to avoid overfitting by shrinking the coefficient estimates to zero. When a model suffers from overfitting, we should control the model's complexity. Technically, regularization avoids overfitting by adding a penalty to the model's loss function: Regularization = Loss Function + Penalty\n",
    "\n",
    "# 46. What is early stopping and how does it relate to regularization?\n",
    "if the model stops developing and begins to perform poorly during training, we cease training. As a result, we “early end” the model. It is a regularization approach that should be used with extreme caution. The main goal is to use early stopping to prevent overfitting. With grade descent, early halting is frequently employed.\n",
    "# 47. Explain the concept of dropout regularization in neural networks.\n",
    "Dropout regularization is a technique to prevent neural networks from overfitting1234. It works by randomly disabling neurons and their corresponding connections, which prevents the network from relying too much on single neurons and forces all neurons to learn to generalize better1. Dropout is a regularization technique that randomly drops out some of the neurons in a neural network during training3. The idea behind dropout is that it forces the network to learn redundant representations of the input data3.\n",
    "# 48. How do you choose the regularization parameter in a model?\n",
    "we can choose the regularization parameter $lambda $ as follows:\n",
    "\n",
    "on the training set, we estimate several different Ridge regressions, with different values of the regularization parameter;\n",
    "\n",
    "on the validation set, we choose the best model (the regularization parameter which gives the lowest MSE on the validation set);\n",
    "\n",
    "on the test set, we check how much overfitting we have done by doing model selection on the validation set.\n",
    "# 49. Whatis the difference between feature selection and regularization?\n",
    " Feature selection, also known as feature subset selection, variable selection, or attribute selection.\n",
    "This approach removes the dimensions (e.g. columns) from the input data and results in a reduced data set for model inference.  Regularization, where we are constraining the solution space while doing optimization.\n",
    "# 50. What is the trade-off between bias and variance in regularized models?\n",
    "There is a tradeoff between a model’s ability to minimize bias and variance which is referred to as the best solution for selecting a value of Regularization constant. A proper understanding of these errors would help to avoid the overfitting and underfitting of a data set while training the algorithm.\n",
    "# SVM:\n",
    "\n",
    "# 51. What is Support Vector Machines (SVM) and how does it work?\n",
    "Support vector machines (SVMs) are a set of supervised learning methods that can be used for classification, regression and outliers detection123. SVMs construct a hyperplane or set of hyperplanes in a high or infinite-dimensional space, which can be used for classification, regression, or other tasks like outliers detection2. SVMs are effective in high dimensional spaces and still effective in cases where the number of dimensions is greater than the number of samples1. SVMs can be used for a variety of tasks, such as text classification, image classification, spam detection, handwriting identification, gene expression analysis, face detection, and anomaly detection4.\n",
    "# 52. How does the kernel trick work in SVM?\n",
    "The kernel trick is a technique that transforms low dimensional input space into a higher dimensional space, where non-separable problems become separable12. The kernel trick allows the SVM algorithm to deal with non-linear separation problems by using a kernel function that computes the similarity between pairs of points in the higher dimensional feature space2. The kernel function does not need to explicitly calculate the transformed feature representation, which saves computation time and memory2\n",
    "# 53. What are support vectors in SVM and why are they important?\n",
    "Support Vectors are data points that lie closest to the hyperplane and are most difficult to classify12. The position of the decision hyperplane depends on the support vectors, and if these support vectors are removed, then it will also change the position of the hyperplane1. The goal of SVM is to maximize the margin between the vectors and the hyperplane, and the hyperplane with maximum margin is called the optimal hyperplane2.\n",
    "# 54. Explain the concept of the margin in SVM and its impact on model performance.\n",
    "The purpose of margins in SVM is to maximize the distance between the hyperplane and the closest data points123. The distance between the vectors and the hyperplane is called the margin1. The hyperplane with maximum margin is called the optimal hyperplane1. A large margin can avoid the effect of random noise and reduce overfitting2. A larger margin will lead to a smaller VC dimension, reduce the number of potential classifiers, and, therefore, reduce the possibility of generalization error2.\n",
    "# 55. How do you handle unbalanced datasets in SVM?\n",
    "My experience is that standard SVM classifiers do not really work nicely on unbalanced data. I encountered that for the C-SVM and it is even worse for the nu-SVM. Maybe you want to have a look at P-SVM which offers a mode that is especially suitable for unbalanced data.\n",
    "# 56. What is the difference between linear SVM and non-linear SVM?\n",
    "The main difference between a linear SVM and a non-linear SVM is that the linear SVM follows a simple rule, where the dot product between two features of its input is equal to the linear combination of its input1. Linear SVM is used when data can be easily separated with a hyperplane by drawing a straight line2. Non-linear SVM, on the other hand, is used when data cannot be separated with a straight line, and kernel functions are used instead2. Non-linear SVMs generally achieve better performance, but linear SVMs are much faster to train3.\n",
    "# 57. What is the role of C-parameter in SVM and how does it affect the decision boundary?\n",
    "For larger values of C, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower C will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. In other words C behaves as a regularization parameter in the SVM.\n",
    "# 58. Explain the concept of slack variables in SVM.\n",
    "In an optimization problem, a slack variable is a variable that is added to an inequality constraint to transform it into an equality1. In SVM, the loss of a misclassified point is called a slack variable and is added to the primal problem that we had for hard margin SVM2.\n",
    "# 59. What is the difference between hard margin and soft margin in SVM?\n",
    "n SVMs, the difference between a hard margin and a soft margin lies in the separability of the data12.Hard margin is used when the data is linearly separable12.Soft margin is used when the data is not linearly separable12. Soft margin is more flexible than hard margin, and allows for some misclassification of data points12. However, it can lead to overfitting or excessive sensitivity to outliers2.\n",
    "# 60. How do you interpret the coefficients in an SVM model?\n",
    "Usually the coefficients of each independent variable tell us the importance of each feature.\n",
    "If you have a very small (close to 0) coefficient associated to an independent variable it's probably due to the fact that the model is not using that variable so much.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f414b68e-a931-4e8c-95b1-8a3983431882",
   "metadata": {},
   "source": [
    "\n",
    "# Decision Trees:\n",
    "\n",
    "# 61. What is a decision tree and how does it work?\n",
    ", a decision tree is a type of flowchart that shows a clear pathway to a decision.\n",
    "In terms of data analytics, it is a type of algorithm that includes conditional ‘control’ statements to classify data.\n",
    "A decision tree starts at a single point (or ‘node’) which then branches (or ‘splits’) in two or more directions.\n",
    "# 62. How do you make splits in a decision tree?\n",
    "A decision tree is a powerful machine learning algorithm extensively used in the field of data science. \n",
    "They are simple to implement and equally easy to interpret. \n",
    "It also serves as the building block for other widely used and complicated machine-learning algorithms like Random Forest, XGBoost, and LightGBM. I often … See more\n",
    "Reduction in Variance in Decision Tree\n",
    "Reduction in Variance is a method for splitting the node used when the target variable is continuous, i.e., regression problems. It is called so because it uses variance as a measure for deciding the feature on which a … See more\n",
    "Basic Decision Tree Terminologies image\n",
    "# 63. What are impurity measures (e.g., Gini index, entropy) and how are they used in decision trees?\n",
    "Impurity measures are used in Decision Trees just like squared loss function in linear regression. We try to arrive at as lowest impurity as possible by the algorithm of our choice. Impurity is presence of more than one class in a subset of data. So all below mentioned measures differ in formula but align in goal.\n",
    "# 64. Explain the concept of information gain in decision trees.\n",
    "Information Gain: Information gain measures the reduction in entropy or variance that results from splitting a dataset based on a specific property. It is used in decision tree algorithms to determine the usefulness of a feature by partitioning the dataset into more homogeneous subsets with respect to the class labels or target variable.\n",
    "# 65. How do you handle missing values in decision trees?\n",
    "There are several ways to handle missing values in decision trees1234:\n",
    "Do not ignore missing values. In your case, they carry important information. Consider (1) binning numeric variables, including a separate bin for 'missing', or (2) impute the missing values with 0, introducing a dummy variable for when the variable is 'missing'.\n",
    "Replace the missing values by an \"outlier\" value.\n",
    "Delete the rows or entire feature with missing values.\n",
    "Replace the missing values with mean/median/mode.\n",
    "Assign an unique category.\n",
    "# 66. What is pruning in decision trees and why is it important?\n",
    "Pruning is a data compression technique in machine learning and search algorithms that reduces the size of decision trees by removing sections of the tree that are non-critical and redundant to classify instances. Pruning reduces the complexity of the final classifier, and hence improves predictive accuracy by the reduction of overfitting.\n",
    "# 67. What is the difference between a classification tree and a regression tree?\n",
    "Classification trees and regression trees are two types of decision trees used in machine learning.\n",
    "The primary difference between the two is that classification trees are built with unordered values with dependent variables, while regression trees take ordered values with continuous values12. Classification algorithms involve decision tree, logistic regression, etc., while regression tree (e.g. Random forest) and linear regression are examples of regression algorithms1. Classification predicts unordered data, while regression predicts ordered data1. Regression can be evaluated using root mean square error1.\n",
    "\n",
    "# 68. How do you interpret the decision boundaries in a decision tree?\n",
    "Decision boundaries are the line or surface that separates the decision space into two or more regions1. Each region is associated with a particular class label. When a new data point is presented, the model predicts the class label of the point based on which region it falls into1. Decision tree does not learn to draw a decision boundary. It tries to split the tree based on the maximum information gain point2. Decision boundary of a decision tree is determined by overlapping orthogonal half-planes (representing the result of each subsequent decision)3.\n",
    "# 69. What is the role of feature importance in decision trees?\n",
    "Feature importance in decision tree is a measure of the contribution of a feature in reducing the impurity12. It is calculated by computing the impurity metric of the node and subtracting the impurity metric of any child nodes2. Feature importance can be used for dimensionality reduction by removing irrelevant features from the model3. It can also be used to explain non-linear models4.\n",
    "# 70. What are ensemble techniques and how are they related to decision trees?\n",
    "Yes, decision trees are commonly used in ensemble methods such as random forests to produce better predictive performance than utilizing a single decision tree123. Ensemble methods combine several models to form a strong learner23. Ensemble techniques have also been used in unsupervised learning scenarios, for example in consensus clustering or in anomaly detection1.\n",
    "\n",
    "# Ensemble Techniques:\n",
    "\n",
    "# 71. What are ensemble techniques in machine learning?\n",
    "Ensemble methods are techniques that create multiple models and then combine them to produce improved results123. \n",
    "They are used in machine learning to improve the accuracy of results in models by combining multiple models instead of using a single model2. Ensemble methods usually produce more accurate solutions than a single model would1. Ensemble learning methods are popular and the go-to technique when the best performance on a predictive modeling project is the most important outcome3.\n",
    "# 72. What is bagging and how is it used in ensemble learning?\n",
    "Bagging is an ensemble learning method that is used to reduce the error by training homogeneous weak learners on different random samples from the training set, in parallel. The results of these base learners are then combined through voting or averaging approach to produce an ensemble model that is more robust and accurate.\n",
    "# 73. Explain the concept of bootstrapping in bagging.\n",
    "Bagging is composed of two parts: aggregation and bootstrapping. Bootstrapping is a sampling method, where a sample is chosen out of a set, using the replacement method. The learning algorithm is then run on the samples selected. The bootstrapping technique uses sampling with replacements to make the selection procedure completely random.\n",
    "# 74. What is boosting and how does it work?\n",
    "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors. In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model tries to compensate for the weaknesses of its predecessor.\n",
    "# 75. What is the difference between AdaBoost and Gradient Boosting?\n",
    "The main differences between Adaboost and Gradient Boosting are12:\n",
    "Gradient Boosting is a generic algorithm to find approximate solutions to the additive modeling problem, while AdaBoost can be seen as a special case with a particular loss function.\n",
    "Gradient Boosting is much more flexible than AdaBoost.\n",
    "The adaptive boosting method minimizes the exponential loss function which changes the algorithm more profound to its outliers. In gradient boosting, the differentiable loss function makes more sensitive to outliers when compared to AdaBoost.\n",
    "Adaboost is computed with a specific loss function and becomes more rigid when comes to few iterations.\n",
    "# 76. What is the purpose of random forests in ensemble learning?\n",
    "Random Forest is an ensemble learning method that combines multiple decision trees123. It is used for various machine learning tasks and is a popular method for classification and regression problems. The training algorithm for random forests applies the general technique of bootstrap aggregating, or bagging, to decision trees1. The random forest model is made up of a large number of small decision trees, called estimators, which each produce their own predictions. The random forest model combines the predictions of the estimators to produce a more accurate prediction3.\n",
    "# 77. How do random forests handle feature importance?\n",
    "In Random Forest, feature importance is computed based on out-of-bag (OOB) error. The random forest model is created and then the OOB error is computed. This is followed by permuting (shuffling) a feature and then again the OOB error is computed. Like wise, all features are permuted one by one1. Feature importance in random forest is usually calculated in two ways: impurity importance (mean decrease impurity) and permutation importance (mean decrease accuracy)2. The impurity importance of each variable is the sum of impurity decrease of all trees when it is selected to split a node2\n",
    "# 78. What is stacking in ensemble learning and how does it work?\n",
    "Stacking is an ensemble machine learning technique that involves combining the predictions of multiple models to build a new model with improved performance123. It is also known as stacked generalization23. Stacking enables us to train multiple models to solve similar problems, and based on their combined output, it builds a new model with improved performance1.\n",
    "ensemble methods because this method focuses on exploring the space of different models applied to the same problem. \n",
    "Basically, the idea behind this method is to handle a machine learning problem using different types of models that are capable of learning to an extent, not the whole space of the problem.\n",
    "# 79. What are the advantages and disadvantages of ensemble techniques?\n",
    "Ensemble techniques can improve the average prediction performance over any contributing member in the ensemble1. \n",
    "The mechanism for improved performance with ensembles is often the reduction in the variance component of prediction errors made by the contributing models1. Ensemble methods include bagging, boosting, and stacking2. Bagging reduces variance and improves accuracy, but can increase bias and may not work well with noisy data2. Boosting improves accuracy and reduces bias, but can overfit with noisy data and outliers2. Stacking improves prediction accuracy by combining models, but can be complex and time-consuming to implement2. \n",
    "Ensemble learning can help project managers to deal with both bias and variance3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf85765-9a17-4f15-beda-df3885d89765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
